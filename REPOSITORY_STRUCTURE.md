# Repository Structure

## Overview

Clean, organized repository for the Esperanto Study ChatGPT conversation dataset.

---

## Directory Structure

```
esperanto/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # Main documentation
â”œâ”€â”€ ğŸ“„ QUICK_START.md              # Quick reference guide
â”œâ”€â”€ ğŸ“„ REPOSITORY_STRUCTURE.md     # This file
â”œâ”€â”€ ğŸ“„ requirements.txt            # Python dependencies
â”œâ”€â”€ ğŸ“„ .gitignore                  # Git ignore rules
â”‚
â”œâ”€â”€ ğŸ”§ data_explorer.py            # Main interactive data explorer (keep in root)
â”‚
â”œâ”€â”€ ğŸ“‚ promptdata/                 # Raw ChatGPT export data
â”‚   â”œâ”€â”€ CSN1/
â”‚   â”‚   â”œâ”€â”€ csn1/
â”‚   â”‚   â”‚   â””â”€â”€ conversations.json
â”‚   â”‚   â””â”€â”€ [archived PNG files]
â”‚   â”œâ”€â”€ CSN2/
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ CSN22/
â”‚
â”œâ”€â”€ ğŸ“‚ output/                     # Processed data files (included in repo)
â”‚   â”œâ”€â”€ matched_conversations.json       # â­ Complete dataset with all matches
â”‚   â”œâ”€â”€ final_participant_summary.csv    # Participant-level data
â”‚   â”œâ”€â”€ conversation_metrics.csv         # Per-conversation metrics
â”‚   â”œâ”€â”€ match_report.json               # Matching statistics
â”‚   â”œâ”€â”€ metrics_summary.json            # Summary by folder
â”‚   â”œâ”€â”€ conversation_analysis.json      # Raw analysis results
â”‚   â””â”€â”€ unmatched_for_review.txt        # List of unmatched conversations
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                    # Data processing pipeline scripts
â”‚   â”œâ”€â”€ analyze_all_data.py             # Step 1: Extract participant IDs
â”‚   â”œâ”€â”€ match_participants.py           # Step 2: Timestamp matching
â”‚   â”œâ”€â”€ aggressive_matcher.py           # Step 3: Aggressive temporal clustering
â”‚   â”œâ”€â”€ extract_missed_ids.py           # Step 4: ID extraction recovery
â”‚   â”œâ”€â”€ ultra_aggressive_matcher.py     # Step 5: Ultra-aggressive matching
â”‚   â”œâ”€â”€ create_final_dataset.py         # Step 6: Generate final outputs
â”‚   â”œâ”€â”€ validate_matching.py            # Validation analysis
â”‚   â”œâ”€â”€ final_validation_report.py      # Comprehensive validation
â”‚   â”œâ”€â”€ deep_unmatched_analysis.py      # Deep dive on unmatched
â”‚   â”œâ”€â”€ explore_data.py                 # Basic data exploration
â”‚   â”œâ”€â”€ generate_metrics.py             # Metrics generation
â”‚   â””â”€â”€ data_explorer_backup.py         # Backup of data explorer
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                       # Documentation
â”‚   â”œâ”€â”€ DATA_EXPLORER_GUIDE.md          # Complete usage guide
â”‚   â”œâ”€â”€ VALIDATION_INSIGHTS.md          # Validation analysis & insights
â”‚   â””â”€â”€ README_old.md                   # Original README (archived)
â”‚
â””â”€â”€ ğŸ“‚ litterature/                # Reference materials
    â””â”€â”€ [research papers, references]
```

---

## File Descriptions

### Root Level

| File | Purpose |
|------|---------|
| `README.md` | Main documentation with overview, usage, and data quality info |
| `QUICK_START.md` | Quick reference for common commands |
| `REPOSITORY_STRUCTURE.md` | This file - repository organization |
| `data_explorer.py` | **Main entry point** - interactive data explorer |
| `requirements.txt` | Python package dependencies |
| `.gitignore` | Git ignore configuration |

### ğŸ“‚ promptdata/

Raw ChatGPT conversation exports organized by study session folder.

**Structure**:
- CSN1-CSN22 folders (21 total)
- Each contains `conversations.json` (some nested in subfolder)
- Archived PNG screenshots of chat interfaces

**Note**: This is the source data - do not modify.

### ğŸ“‚ output/

Processed data files ready for analysis.

| File | Records | Description |
|------|---------|-------------|
| `matched_conversations.json` | 397 | **Primary dataset** - all conversations with participant matches |
| `final_participant_summary.csv` | 285 | Participant-level aggregated statistics |
| `conversation_metrics.csv` | 397 | Individual conversation metrics |
| `match_report.json` | - | Detailed matching method statistics |
| `metrics_summary.json` | 21 | Summary statistics by folder |
| `conversation_analysis.json` | 397 | Raw analysis with ID extraction results |
| `unmatched_for_review.txt` | 13 | List of unmatched conversations |

**Primary file**: `matched_conversations.json` contains all data with:
- Participant IDs
- Match methods and confidence scores
- Message counts, timestamps, titles
- Full metadata

### ğŸ“‚ scripts/

Data processing pipeline in execution order:

| Script | Phase | Purpose |
|--------|-------|---------|
| `analyze_all_data.py` | 1 | Extract participant IDs from messages (12+ format patterns) |
| `match_participants.py` | 2 | Timestamp proximity matching (60-min window) |
| `aggressive_matcher.py` | 3 | Aggressive temporal clustering (120-min window) |
| `extract_missed_ids.py` | 4 | Parse malformed IDs from messages |
| `ultra_aggressive_matcher.py` | 5 | Ultra-aggressive matching (6-hour + content similarity) |
| `create_final_dataset.py` | 6 | Generate final CSV and JSON outputs |
| `validate_matching.py` | - | Validation analysis tool |
| `final_validation_report.py` | - | Comprehensive validation report generator |
| `deep_unmatched_analysis.py` | - | Detailed analysis of unmatched conversations |
| `explore_data.py` | - | Basic data exploration utilities |
| `generate_metrics.py` | - | Metrics calculation |

**Run order** (already completed):
```bash
cd scripts
python analyze_all_data.py
python match_participants.py
python aggressive_matcher.py
python extract_missed_ids.py
python ultra_aggressive_matcher.py
python create_final_dataset.py
python final_validation_report.py
```

**Output**: All results saved to `output/` folder

### ğŸ“‚ docs/

Comprehensive documentation:

| Document | Purpose |
|----------|---------|
| `DATA_EXPLORER_GUIDE.md` | Complete guide to using data_explorer.py |
| `VALIDATION_INSIGHTS.md` | Deep validation analysis comparing known correct vs reconstructed data |
| `README_old.md` | Original README (archived) |

### ğŸ“‚ litterature/

Research papers, references, and supporting materials for the study.

---

## Key Design Decisions

### Why data_explorer.py is in root?
- **Main entry point** for users
- Easy to run: `python data_explorer.py`
- No need to navigate to subdirectories

### Why keep output/ in repository?
- **Processed data is valuable** - represents significant computation
- **Reproducibility** - users can immediately explore without running pipeline
- **Small size** - JSON/CSV files are manageable in git
- **Version control** - track changes in processed data

### Why separate scripts/ folder?
- **Organization** - processing scripts separate from end-user tools
- **Advanced users only** - most users just need data_explorer.py
- **Pipeline clarity** - numbered/named scripts show processing order

---

## Usage Patterns

### For Data Consumers (Most Users)

1. Read `README.md` for overview
2. Check `QUICK_START.md` for commands
3. Run `python data_explorer.py`
4. Explore data interactively or via commands
5. Use files from `output/` folder for analysis

### For Data Processors (Advanced)

1. Review `scripts/` folder
2. Run pipeline scripts in order (if reprocessing needed)
3. Check `docs/VALIDATION_INSIGHTS.md` for methodology
4. Modify scripts for custom processing

### For Researchers

1. Read `README.md` and `docs/VALIDATION_INSIGHTS.md`
2. Understand data quality levels
3. Use `output/matched_conversations.json` as primary source
4. Filter by confidence scores for analysis needs
5. Cite properly

---

## Git Strategy

### Included in Repository
- âœ… All documentation
- âœ… All scripts
- âœ… All output files (processed data)
- âœ… data_explorer.py
- âœ… requirements.txt

### Excluded from Repository (.gitignore)
- âŒ `__pycache__/` and Python bytecode
- âŒ Virtual environments
- âŒ Temporary files
- âŒ IDE-specific files
- âŒ OS-specific files (DS_Store, Thumbs.db)

### Raw Data (promptdata/)
- **Included** but can be large
- Contains original ChatGPT exports
- Required for pipeline reprocessing

---

## Data Flow

```
promptdata/CSN*/conversations.json
           â†“
    [analyze_all_data.py]
           â†“
    conversation_analysis.json
           â†“
    [match_participants.py]
           â†“
    [aggressive_matcher.py]
           â†“
    [extract_missed_ids.py]
           â†“
    [ultra_aggressive_matcher.py]
           â†“
    matched_conversations.json (primary)
           â†“
    [create_final_dataset.py]
           â†“
    â”œâ”€â”€ final_participant_summary.csv
    â”œâ”€â”€ conversation_metrics.csv
    â”œâ”€â”€ match_report.json
    â””â”€â”€ metrics_summary.json
           â†“
    [data_explorer.py] â† User interacts here
```

---

## Quick Navigation

| I want to... | Go to... |
|--------------|----------|
| Explore data | Run `python data_explorer.py` |
| Understand data quality | Read `docs/VALIDATION_INSIGHTS.md` |
| Learn commands | Check `QUICK_START.md` |
| Access raw data | See `promptdata/` |
| Get processed data | Use `output/matched_conversations.json` |
| Understand processing | Review `scripts/` in order |
| Cite the dataset | See `README.md` citation section |

---

## Statistics Summary

- **Total files**: ~50+ (including all conversations.json)
- **Main entry point**: `data_explorer.py`
- **Primary dataset**: `output/matched_conversations.json` (397 conversations)
- **Documentation**: 4 markdown files
- **Processing scripts**: 11 Python files
- **Output files**: 7 data files

---

*Repository organized for clarity, usability, and reproducibility.*
*Last updated: December 5, 2024*
